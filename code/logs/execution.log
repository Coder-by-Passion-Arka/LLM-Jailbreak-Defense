2026-02-10 23:10:34,535 - INFO - pipeline - [SYSTEM] ğŸ“‚ Loading Datasets...
2026-02-10 23:10:46,959 - INFO - pipeline - [SYSTEM] ğŸ“ˆ Loading Judge Model...
2026-02-10 23:10:46,960 - INFO - judge - [JUDGE] âš–ï¸  Initializing Smart Judge with Auto-Hardware Detection...
2026-02-10 23:10:47,254 - INFO - judge - [JUDGE] ğŸ” Detected System: VRAM=4.0GB, RAM=15.6GB
2026-02-10 23:10:47,254 - INFO - judge - [JUDGE] ğŸ“¥ Fetching CPU model: llama-2-7b.Q4_K_M.gguf...
2026-02-10 23:11:02,238 - INFO - judge - [JUDGE] âœ… Loaded Llama-Guard-3-1B on CPU.
2026-02-10 23:11:02,242 - INFO - pipeline - [SYSTEM] ğŸ›¡ï¸ Loading Defense Layer...
2026-02-10 23:11:02,243 - INFO - defensive_layer - [DEFENSE] ğŸ›¡ï¸ Defense Layer Initialized (Mock Mode)
2026-02-10 23:11:02,244 - INFO - pipeline - 
============================================================
[TARGET] ğŸ¯ Loading Target Model: Qwen/Qwen1.5-0.5B-Chat-AWQ
============================================================
2026-02-10 23:11:24,220 - ERROR - pipeline - Failed to load Qwen/Qwen1.5-0.5B-Chat-AWQ: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.
2026-02-10 23:11:24,275 - WARNING - pipeline - [SYSTEM] No results generated (All models failed?)
